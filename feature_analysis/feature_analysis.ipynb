{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_name = \"TEST\"\n",
    "X_test_path = \"C:/Users/elise/OneDrive - NTNU/Documents/A.NTNU10/forest_classification/data/TEST/HYPSO_final_107bands_X_test_TEST.npy\"\n",
    "X_train_path = \"C:/Users/elise/OneDrive - NTNU/Documents/A.NTNU10/forest_classification/data/TEST/HYPSO_final_107bands_X_train_TEST.npy\"\n",
    "y_test_path = \"C:/Users/elise/OneDrive - NTNU/Documents/A.NTNU10/forest_classification/data/TEST/HYPSO_final_y_test_TEST.npy\"\n",
    "y_train_path = \"C:/Users/elise/OneDrive - NTNU/Documents/A.NTNU10/forest_classification/data/TEST/HYPSO_final_y_train_TEST.npy\"\n",
    "\n",
    "wavelength_file = \"C:/Users/elise/Master/HYPSO/spectral_bands_HYPSO-1_v1.npz\"\n",
    "\n",
    "dir_path = f\"C:/Users/elise/OneDrive - NTNU/Documents/A.NTNU10/Code/Preprocessing/comb{comb_name}/\"\n",
    "\n",
    "output_file = f\"{dir_path}{comb_name}info.txt\"\n",
    "\n",
    "label_names = {0: \"Coniferous\", 1: \"Deciduous\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(X_train_path)\n",
    "X_test = np.load(X_test_path)\n",
    "y_train = np.load(y_train_path)\n",
    "y_test = np.load(y_test_path)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels, count = np.unique(y_train, return_counts=True)\n",
    "count_classes = len(unique_labels)\n",
    "\n",
    "print(unique_labels)\n",
    "print(count)\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate colors from Viridis colormap\n",
    "unique_labels = np.unique(y_train)\n",
    "viridis_colors = cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "print(viridis_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load band numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satellite bands (wavelengths in nanometers)\n",
    "all_wavelengths = np.load(wavelength_file)[\"arr_0\"]\n",
    "print(f\"Number of bands: {len(all_wavelengths)}\")\n",
    "\n",
    "bands_to_remove = [0,1,2,3,4,5, 106, 107, 108, 109, 119, 118, 117]\n",
    "wavelengths = np.delete(all_wavelengths, bands_to_remove, axis=0)\n",
    "print(f\"Number of bands after removal: {len(wavelengths)}\")\n",
    "band_nrs = np.delete(np.arange(len(all_wavelengths)), bands_to_remove, axis=0) + 1\n",
    "print(f\"Band numbers after removal: {band_nrs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot spectral signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectral_signatures(input_array, label_array, save_name, labels=[1, 2, 3], pixel_nr = -1):\n",
    "    \"\"\"\n",
    "    Plots the spectral response of random pixels for specified labels.\n",
    "    \n",
    "    Args:\n",
    "        landsat_array (numpy array): 3D array (bands, height, width) of Landsat data.\n",
    "        label_array (numpy array): 2D array (height, width) of label values.\n",
    "        labels (list of int): List of label values to compare.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    for i, label_x in enumerate(labels):\n",
    "        # Find pixels with the specified label\n",
    "        pixel_indices = np.argwhere(label_array == label_x)\n",
    "\n",
    "        if pixel_indices.size == 0:\n",
    "            print(f\"No pixels found with label {label_x}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Select a random pixel\n",
    "        indice = pixel_indices[random.randint(0, pixel_indices.shape[0] - 1) if pixel_nr == -1 else pixel_nr]\n",
    "        # indice = pixel_indices[0]\n",
    "\n",
    "        print(f\"Selected pixel for {label_names.get(label_x, 'Unknown')}: {indice}\")\n",
    "\n",
    "        # Extract spectral values for the pixel\n",
    "        spectrum = input_array[indice, :].flatten()\n",
    "\n",
    "        # Plot the spectrum with Viridis colors\n",
    "        plt.plot(\n",
    "            wavelengths, spectrum, marker='o', linestyle='-',\n",
    "            color=viridis_colors[i], label=f\"{label_names.get(label_x, 'Unknown')}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    # Labels and formatting\n",
    "    plt.xlabel(\"Wavelength (nm)\")\n",
    "    plt.ylabel(\"Reflectance\")\n",
    "    plt.title(\"Spectral Response\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{dir_path}{comb_name}spectral_signatures_{save_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Function to compute statistics\n",
    "def compute_spectral_statistics(input_array, label_array, labels=[0, 1]):\n",
    "    stats = {}\n",
    "    for label in labels:\n",
    "        mask = label_array == label\n",
    "        if np.sum(mask) == 0:\n",
    "            print(f\"No pixels found for {label_names[label]}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        spectra = input_array[mask, :]\n",
    "        mean_spectrum = np.mean(spectra, axis=0)\n",
    "        std_spectrum = np.std(spectra, axis=0)\n",
    "        \n",
    "        stats[label] = {\n",
    "            \"mean\": mean_spectrum,\n",
    "            \"std\": std_spectrum\n",
    "        }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectral_signatures(X_train, y_train, \"all\", labels=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics\n",
    "spectral_stats = compute_spectral_statistics(X_train, y_train)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "dataframes = {}\n",
    "for label, stats in spectral_stats.items():\n",
    "    df = pd.DataFrame({\n",
    "        \"Wavelength (nm)\": wavelengths,\n",
    "        \"Mean Reflectance\": stats[\"mean\"],\n",
    "        \"Std Dev\": stats[\"std\"]\n",
    "    })\n",
    "    dataframes[label] = df\n",
    "    # Save info in file\n",
    "    df.to_csv(f\"{dir_path}{comb_name}stats_{label_names[label]}.csv\", index=False)\n",
    "    print(f\"Spectral Statistics for {label_names[label]}:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "# Plot the mean spectral signatures\n",
    "plt.figure(figsize=(8, 5))\n",
    "viridis_colors = cm.viridis(np.linspace(0, 1, len(label_names)))\n",
    "for i, (label, stats) in enumerate(spectral_stats.items()):\n",
    "    plt.plot(\n",
    "        wavelengths, stats[\"mean\"], marker='o', linestyle='-',\n",
    "        color=viridis_colors[i], label=f\"{label_names[label]}\"\n",
    "    )\n",
    "    plt.fill_between(wavelengths, stats[\"mean\"] - stats[\"std\"], stats[\"mean\"] + stats[\"std\"], color=viridis_colors[i], alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Reflectance\")\n",
    "plt.title(\"Mean Spectral Response with Variance\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(f\"{dir_path}{comb_name}spectral_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle('Variance of bands within each class')\n",
    "viridis_colors = cm.viridis(np.linspace(0, 1, len(label_names)))\n",
    "for i, (label, stats) in enumerate(spectral_stats.items()):\n",
    "    plt.subplot(2, 1, i + 1)\n",
    "    plt.subplots_adjust(hspace=0.5)  # Add more space between subplots\n",
    "    plt.plot(\n",
    "        wavelengths, stats[\"std\"], marker='o', linestyle='-',\n",
    "        color=viridis_colors[i], label=f\"{label_names[label]}\"\n",
    "    )\n",
    "    plt.title(f'{label_names[label]}')\n",
    "    plt.xlabel(\"Wavelength (nm)\")\n",
    "    plt.ylabel(\"Standard Deviation\")\n",
    "\n",
    "plt.savefig(f\"{dir_path}{comb_name}variance_bands_within_class.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "sensor_name = \"Hypso\"\n",
    "\n",
    "# Save wavelengths and spectral statistics\n",
    "data_to_save = {\n",
    "    \"wavelengths\": wavelengths,  # Adjust this for different sensors\n",
    "    \"spectral_stats\": spectral_stats\n",
    "}\n",
    "\n",
    "#save in \"Dataset\" folder\n",
    "with open(f\"C:/Users/elise/OneDrive - NTNU/Documents/A.NTNU10/Code/Dataset/spectral_data_{sensor_name}_{comb_name}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_to_save, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca_components = pca.fit_transform(X_train)\n",
    "\n",
    "# Get absolute contributions (loadings)\n",
    "contribution = np.abs(pca.components_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Viridis colormap\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 4))\n",
    "\n",
    "# Plot loadings for the first four principal components using stem plots\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.stem(band_nrs, contribution[0, :], label=\"PC1\", linefmt='-', markerfmt='o', basefmt='b-')\n",
    "plt.title(\"Loadings for Principal Component 1\")\n",
    "plt.xlabel(\"Spectral Band\")\n",
    "plt.ylabel(\"Contribution\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{dir_path}{comb_name}pc1.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.stem(band_nrs, contribution[1, :], label=\"PC2\", linefmt='-', markerfmt='o', basefmt='b-')\n",
    "plt.title(\"Loadings for Principal Component 2\")\n",
    "plt.xlabel(\"Spectral Band\")\n",
    "plt.ylabel(\"Contribution\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{dir_path}{comb_name}pc2.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.stem(band_nrs, contribution[2, :], label=\"PC3\", linefmt='-', markerfmt='o', basefmt='b-')\n",
    "plt.title(\"Loadings for Principal Component 3\")\n",
    "plt.xlabel(\"Spectral Band\")\n",
    "plt.ylabel(\"Contribution\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{dir_path}{comb_name}pc3.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.stem(band_nrs, contribution[3, :], label=\"PC4\", linefmt='-', markerfmt='o', basefmt='b-')\n",
    "plt.title(\"Loadings for Principal Component 4\")\n",
    "plt.xlabel(\"Spectral Band\")\n",
    "plt.ylabel(\"Contribution\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{dir_path}{comb_name}pc4.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components_0   = []\n",
    "pca_components_1   = []\n",
    "\n",
    "for i in range(len(y_train)): \n",
    "    if y_train[i] == 0:\n",
    "        pca_components_0.append(pca_components[i, :])\n",
    "    elif y_train[i] == 1:\n",
    "        pca_components_1.append(pca_components[i, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean, corresponting to how much each PC typically is used to descripe each class, uses median instead of mean to be more robust to noise\n",
    "pca_components_1_mean =   np.median(np.array(pca_components_1),   axis=0)\n",
    "pca_components_0_mean =  np.median(np.array(pca_components_0),  axis=0)\n",
    "\n",
    "# compute the difference in PCs between each class\n",
    "tot_diff = np.abs(pca_components_1_mean - pca_components_0_mean) # sum differences linearly\n",
    "\n",
    "# Here we see that the variance within a class mostly lies in the first PCs, this should maybe be incorporated into the decision..\n",
    "plt.figure()\n",
    "plt.suptitle('Variance of principal components within each class')\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(np.var(np.array(pca_components_0), axis=0), color=viridis_colors[0])\n",
    "plt.title(f'{label_names[0]}')\n",
    "plt.yscale('log')\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(np.var(np.array(pca_components_1), axis=0), color=viridis_colors[1])\n",
    "plt.title(f'{label_names[1]}')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f\"{dir_path}{comb_name}variance_within_class.png\")\n",
    "plt.show()\n",
    "\n",
    "percent_var_0 = np.var(np.array(pca_components_0), axis=0)/np.abs(np.array(pca_components_0_mean)) * 100\n",
    "percent_var_1 = np.var(np.array(pca_components_1), axis=0)/np.abs(np.array(pca_components_1_mean)) * 100\n",
    "\n",
    "print(f\"Percent variance compared to mean per PC for {label_names[1]}: {percent_var_1}\")\n",
    "print(f\"Percent variance compared to mean per PC for {label_names[0]}: {percent_var_0}\")                                                               \n",
    "\n",
    "plt.figure()\n",
    "plt.title('PCs weighted based on importance for classifying tree species')\n",
    "plt.stem(tot_diff[:10], linefmt='-', markerfmt='o', basefmt='b-')\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Weighted Importance\")\n",
    "plt.savefig(f\"{dir_path}{comb_name}pcs_importance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.stem(range(len(explained_variance[:15])), explained_variance[:15], linefmt='-', markerfmt='o', basefmt='b-')\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"Explained Variance by Principal Components\")\n",
    "plt.grid()\n",
    "plt.savefig(f\"{dir_path}{comb_name}explained_variance.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.cumsum(explained_variance), marker='o', color=viridis_colors[0])\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Cumulative Explained Variance by Principal Components\")\n",
    "plt.grid()\n",
    "plt.savefig(f\"{dir_path}{comb_name}cumulative_explained_variance.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.cumsum(explained_variance)[:15], marker='o', color=viridis_colors[0])\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Cumulative Explained Variance by Principal Components\")\n",
    "plt.grid()\n",
    "plt.savefig(f\"{dir_path}{comb_name}cumulative_explained_variance_15.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "constant_idx = 10  # Number of components to keep for the PCA\n",
    "# Compute cumulative explained variance\n",
    "var_threshold = 0.95\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "idx_threshold = np.argmax(cumulative_variance >= var_threshold) + 1\n",
    "print(f\"95% of variance can be explained with {idx_threshold} principal components\")\n",
    "\n",
    "# Write to file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(f'\\n\\n{var_threshold*100}% of variance can be explained with {idx_threshold} principal components:\\n')\n",
    "    for i in range(idx_threshold):\n",
    "        file.write(f\"{i+1}. PC {i}\\n\")  # Principal components are naturally ordered\n",
    "\n",
    "# Select the top `idx_threshold` principal components\n",
    "pca_X_train_threshold = X_train[:, :idx_threshold]  # Select first idx_threshold components\n",
    "print(f\"Shape of original train data: {X_train.shape}\")\n",
    "print(f\"Shape of reduced train data for threshold idx: {pca_X_train_threshold.shape}\")\n",
    "\n",
    "pca_X_test_threshold = pca.transform(X_test)[:, :idx_threshold]  # Same for test data\n",
    "print(f\"Shape of original test data: {X_test.shape}\")\n",
    "print(f\"Shape of reduced test data for threshold idx: {pca_X_test_threshold.shape}\")\n",
    "\n",
    "pca_X_train_constant = X_train[:, :constant_idx]  \n",
    "print(f\"Shape of reduced train data for constant idx: {pca_X_train_constant.shape}\")\n",
    "\n",
    "pca_X_test_constant = pca.transform(X_test)[:, :constant_idx]\n",
    "print(f\"Shape of reduced test data for constant idx: {pca_X_test_constant.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top contributing PCs to class differences\n",
    "top_pcs = np.argsort(tot_diff)[::-1]  # Sort by highest difference\n",
    "\n",
    "# Print top 5 PCs that explain most variance between classes\n",
    "print(\"Top 5 Principal Components for Class Differentiation:\", top_pcs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the two most important PCs\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(pca_components[:, top_pcs[0]], pca_components[:, top_pcs[1]], c=y_train, cmap=cm.colors.ListedColormap([viridis_colors[0], viridis_colors[1]]), alpha=0.7)\n",
    "cbar = plt.colorbar(scatter, ticks=[0, 1])\n",
    "cbar.ax.set_yticklabels([label_names[0], label_names[1]])\n",
    "plt.xlabel(f\"Principal Component {top_pcs[0]+1}\")\n",
    "plt.ylabel(f\"Principal Component {top_pcs[1]+1}\")\n",
    "plt.title(\"Scatter Plot of the Two Most Important PCs\")\n",
    "plt.savefig(f\"{dir_path}{comb_name}scatter_2D.png\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of the three most important PCs\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(pca_components[:, top_pcs[0]], pca_components[:, top_pcs[1]], pca_components[:, top_pcs[2]], c=y_train, cmap=cm.colors.ListedColormap([viridis_colors[0], viridis_colors[1]]), alpha=0.7)\n",
    "cbar = plt.colorbar(scatter, ticks=[0, 1])\n",
    "cbar.ax.set_yticklabels([label_names[0], label_names[1]])\n",
    "ax.set_xlabel(f\"Principal Component {top_pcs[0]+1}\")\n",
    "ax.set_ylabel(f\"Principal Component {top_pcs[1]+1}\")\n",
    "ax.set_zlabel(f\"Principal Component {top_pcs[2]+1}\")\n",
    "plt.title(\"Scatter Plot of the Three Most Important PCs\")\n",
    "plt.savefig(f\"{dir_path}{comb_name}scatter_3D.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Normalize the loadings for each PC (each row sums to 1)\n",
    "contribution_normalized = contribution / contribution.sum(axis=1, keepdims=True)\n",
    "\n",
    "# 2. Calculate weighted contributions for each wavelength:\n",
    "# Each PCâ€™s weight is given by its explained variance (explained_variance_ordered)\n",
    "weighted_wavelengths = pca.explained_variance_ratio_ @ contribution_normalized\n",
    "\n",
    "# 3. Sort wavelengths in descending order of weighted contribution\n",
    "sorted_indices = np.argsort(weighted_wavelengths)[::-1]\n",
    "\n",
    "# Calculate the cumulative weighted contribution\n",
    "total_weight = np.sum(weighted_wavelengths)\n",
    "cumulative_weight = np.cumsum(weighted_wavelengths[sorted_indices])\n",
    "\n",
    "# 4. Determine the number of bands required to reach the desired threshold (e.g., 95%)\n",
    "var_threshold = 0.8\n",
    "idx_threshold = np.searchsorted(cumulative_weight, var_threshold * total_weight) + 1\n",
    "\n",
    "# Get the indices of the selected bands\n",
    "selected_indices = sorted_indices[:idx_threshold]\n",
    "band_indices = band_nrs[selected_indices]  # Assuming 'band_nrs' maps to original wavelength indices\n",
    "\n",
    "print(f\"Band indices: {band_indices}\")\n",
    "print(f\"{var_threshold*100}% of variance can be explained with {idx_threshold} bands\")\n",
    "\n",
    "# 5. Reduce the training and test data to only the selected bands\n",
    "# (Assuming rows correspond to wavelengths in your data matrices)\n",
    "reduced_X_train = X_train[:, selected_indices]\n",
    "reduced_X_test = X_test[:, selected_indices]\n",
    "\n",
    "print(f\"Shape of original train data: {X_train.shape}\")\n",
    "print(f\"Shape of reduced train data: {reduced_X_train.shape}\")\n",
    "print(f\"Shape of original test data: {X_test.shape}\")\n",
    "print(f\"Shape of reduced test data: {reduced_X_test.shape}\")\n",
    "\n",
    "# 6. Plot the explained variance per band and cumulative explained variance\n",
    "plt.figure()\n",
    "plt.stem(weighted_wavelengths[sorted_indices][:idx_threshold])\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('Band')\n",
    "plt.savefig(f\"{dir_path}{comb_name}explained_variance_per_band.png\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cumulative_weight[:idx_threshold], marker='o')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.xlabel('Band')\n",
    "plt.savefig(f\"{dir_path}{comb_name}cumulative_explained_variance_bands.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "with open(output_file, \"a\") as file:\n",
    "    file.write(f'\\n\\n{var_threshold*100}% of variance can be explained with {idx_threshold} bands:\\n')\n",
    "    for i, band in enumerate(band_indices):\n",
    "        file.write(f\"{i+1}. Band {band}, {all_wavelengths[band-1]} nm\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectral_signatures(X_train, y_train, \"with_bands\", labels=[1], pixel_nr=0)\n",
    "\n",
    "# Create a mask of all indices\n",
    "mask = np.ones(X_train.shape[1], dtype=bool)  # True for all bands initially\n",
    "mask[selected_indices] = False  # Set selected bands to False (they remain unchanged)\n",
    "\n",
    "# Copy data\n",
    "reduced_data = np.copy(X_train)\n",
    "\n",
    "# Set non-selected indices to zero\n",
    "reduced_data[:, mask] = 0  \n",
    "\n",
    "print(f\"Selected indices: {selected_indices}\")\n",
    "print(f\"Shape of original train data: {X_train.shape}\")\n",
    "print(f\"Shape of reduced train data: {reduced_data.shape}\")\n",
    "\n",
    "\n",
    "plot_spectral_signatures(reduced_data, y_train, \"removed_bands\", labels=[1], pixel_nr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes\n",
    "print(f\"Shape of original train data: {X_train.shape}\")\n",
    "print(f\"Shape of original test data: {X_test.shape}\")\n",
    "\n",
    "print(f\"Shape of pca 10 train data: {pca_X_train_constant.shape}\")\n",
    "print(f\"Shape of pca 10 train data: {pca_X_test_constant.shape}\")\n",
    "print(f\"Shape of pca threshold train data: {pca_X_train_threshold.shape}\")\n",
    "print(f\"Shape of pca threshold test data: {pca_X_test_threshold.shape}\")\n",
    "print(f\"Shape of reduced train data: {reduced_X_train.shape}\")\n",
    "print(f\"Shape of reduced test data: {reduced_X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy arrays\n",
    "\n",
    "# train_model(pca_X_train, pca_X_test, y_train, y_test,\"pca_\")\n",
    "np.save(f\"{dir_path}{comb_name}_X_train_pca_{constant_idx}.npy\", pca_X_train_constant)\n",
    "np.save(f\"{dir_path}{comb_name}_X_test_pca_{constant_idx}.npy\", pca_X_test_constant)\n",
    "\n",
    "# train_model(pca_X_train_threshold, pca_X_test_threshold, y_train, y_test,\"pca_\")\n",
    "np.save(f\"{dir_path}{comb_name}_X_train_pca_threshold_{idx_threshold}.npy\", pca_X_train_threshold)\n",
    "np.save(f\"{dir_path}{comb_name}_X_test_pca_threshold_{idx_threshold}.npy\", pca_X_test_threshold)\n",
    "\n",
    "# train_model(reduced_X_train.T, reduced_X_test.T, y_train, y_test,\"reduced_\")\n",
    "np.save(f\"{dir_path}{comb_name}_X_train_reduced_80.npy\", reduced_X_train)\n",
    "np.save(f\"{dir_path}{comb_name}_X_test_reduced_80.npy\", reduced_X_test)\n",
    "\n",
    "np.save(f\"{dir_path}{comb_name}_y_train.npy\", y_train)\n",
    "np.save(f\"{dir_path}{comb_name}_y_test.npy\", y_test)\n",
    "\n",
    "print(\"Data saved successfully!\")\n",
    "print(f\"Data saved to {dir_path}{comb_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
