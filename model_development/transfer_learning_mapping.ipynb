{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License and Attribution\n",
    "\n",
    "This notebook is adapted from:\n",
    "- MobileNet-1D-2D-Tensorflow-Keras by Sakib Mahmud  \n",
    "  GitHub: https://github.com/Sakib1263/MobileNet-1D-2D-Tensorflow-Keras  \n",
    "  Licensed under the Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)\n",
    "  See the [LICENSE](../LICENSE) file for full terms and conditions.\n",
    "\n",
    "\n",
    "## Modifications Made by Elise Mj√∏en\n",
    "\n",
    "This version includes substantial modifications, including:\n",
    "- Data loading and preprocessing\n",
    "- Performance evaluation and comparison\n",
    "- Model saving and logging of hyperparameters\n",
    "- Transfer learning functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc, precision_recall_curve, average_precision_score\n",
    "import torch\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU/CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Is CUDA enabled GPU Available?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Number:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU Index:\", torch.cuda.current_device())\n",
    "    print(\"GPU Type:\", torch.cuda.get_device_name(device=None))\n",
    "    print(\"GPU Capability:\", torch.cuda.get_device_capability(device=None))\n",
    "    print(\"Is GPU Initialized yet?\", torch.cuda.is_initialized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = \"Landsat\"\n",
    "sat_comb = \"Hypso_filter\"\n",
    "hypso_comb = \"all_filtered_reflectance\"\n",
    "dr_type = \"original\"\n",
    "\n",
    "dir_name = f\"{sensor}/{sat_comb}/{dr_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing classification reports if the file exists\n",
    "classification_reports_path = f\"{dir_name}/classification_reports.json\"\n",
    "if os.path.exists(classification_reports_path):\n",
    "    with open(classification_reports_path, \"r\") as json_file:\n",
    "        classification_reports = json.load(json_file)\n",
    "else:\n",
    "    classification_reports = {}\n",
    "\n",
    "model_version = classification_reports[0][0]\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(f\"./data/{hypso_comb}_X_train_{dr_type}.npy\")\n",
    "X_test = np.load(f\"./data/{hypso_comb}_X_test_{dr_type}.npy\")\n",
    "y_train = np.load(f\"./data/{hypso_comb}_y_train_{dr_type}.npy\")\n",
    "y_test = np.load(f\"./data/{hypso_comb}_y_test_{dr_type}.npy\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "  L_E = LabelEncoder()\n",
    "  integer_encoded = L_E.fit_transform(data)  \n",
    "  onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "  one_hot_encoded_data = onehot_encoder.fit_transform(integer_encoded)\n",
    "  return one_hot_encoded_data\n",
    "\n",
    "y_train_encoded = one_hot_encoding(y_train.ravel())\n",
    "y_test_encoded = one_hot_encoding(y_test.ravel())\n",
    "\n",
    "\n",
    "print(y_train_encoded.shape)\n",
    "print(y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model\n",
    "model_version = classification_reports[0][0]\n",
    "base_model = tf.keras.models.load_model(f\"{dir_name}/{model_version}.keras\")\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (X_train.shape[1], 1)  # Hyperspectral input\n",
    "print(input_shape)\n",
    "base_model_input = base_model.input  # Get the original input layer of base model\n",
    "print(base_model_input)\n",
    "\n",
    "\n",
    "# New input layer\n",
    "inputs = keras.Input(shape=input_shape, name=\"hyperspectral_input\")\n",
    "\n",
    "# Fully connected mapping layer (trainable)\n",
    "# mapped_features = layers.Lambda(lambda x: tf.squeeze(x, axis=-1))(inputs)\n",
    "mapped_features = layers.Reshape((-1,))(inputs)  # Removes last dimension safely\n",
    "mapped_features = layers.Dense(5, activation=\"relu\", name=\"band_mapping\")(mapped_features)\n",
    "mapped_features = layers.Reshape((5, 1))(mapped_features)\n",
    "mapped_features = layers.BatchNormalization()(mapped_features)  # Normalize for stability\n",
    "mapped_features = layers.Dropout(0.2)(mapped_features)  # Optional regularization\n",
    "\n",
    "# Extract the layers of base_model while keeping its input\n",
    "new_features = base_model(mapped_features, training=False)  # Ensure inference mode\n",
    "new_model = tf.keras.Model(inputs=inputs, outputs=new_features, name=\"HS_to_MS\")\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "# Freeze middle layers only\n",
    "for layer in base_model.layers[:-5]:  # Adjust indices based on your model structure\n",
    "    layer.trainable = False\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "gamma = 4\n",
    "learning_rate = 1e-5\n",
    "new_model.compile(\n",
    "    loss=keras.losses.CategoricalFocalCrossentropy(gamma=gamma),\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "    metrics=['mse', 'accuracy']\n",
    ")\n",
    "\n",
    "# Model saving parameters\n",
    "fine_tune_epochs = 20\n",
    "initial_epochs = 50\n",
    "trainable_layer_start_idx = -54\n",
    "save_model_version = classification_reports[0][0] + f\"_tl_ie{initial_epochs}_fte{fine_tune_epochs}_g{gamma}_lr{learning_rate}_tbl{trainable_layer_start_idx}_mapping\"\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, mode='min'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(f\"{dir_name}/{save_model_version}_tl.keras\", verbose=1, monitor='val_loss', save_best_only=True, mode='min')\n",
    "]\n",
    "\n",
    "# Train the new model\n",
    "history = new_model.fit(\n",
    "    X_train, y_train_encoded,\n",
    "    epochs=initial_epochs,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unfreeze middle layers\n",
    "for layer in base_model.layers[trainable_layer_start_idx:]:  # Adjust indices based on your model structure\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True  # Unfreeze non-BatchNorm layers\n",
    "        print(layer)\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "fine_tune_epochs = 20\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "new_model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              loss=keras.losses.CategoricalFocalCrossentropy(gamma = gamma),\n",
    "                             metrics=['mse', 'accuracy'])\n",
    "\n",
    "# Fine-tune the entire model\n",
    "callbacks_fine = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, mode='min')]\n",
    "history_fine = new_model.fit(X_train, y_train_encoded, epochs=total_epochs, initial_epoch=len(history.epoch), batch_size=128, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions from the Test Set from the Trained Model\n",
    "best_model_tl = tf.keras.models.load_model(f\"{dir_name}/{save_model_version}_tl.keras\")\n",
    "Predictions = best_model_tl.predict(X_test, verbose=1)\n",
    "print(Predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error of the prediction, one of many evaluation metrics\n",
    "# Using Mean Absolute Error (MAE) in this case as a sample\n",
    "Error_tl = mean_absolute_error(y_test_encoded, Predictions)\n",
    "print(f\"MAE_tl: {Error_tl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(history):\n",
    "  # list all dictionaries in history\n",
    "  print(history.history.keys())\n",
    "  # summarize history for error\n",
    "  plt.figure(figsize=(12,10))\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.plot(history.history['mse'])\n",
    "  plt.plot(history.history['val_mse'])\n",
    "  plt.title('Model Error Performance')\n",
    "  plt.ylabel('Error')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper right')\n",
    "  plt.show()\n",
    "  # summarize history for loss\n",
    "  plt.figure(figsize=(12,10))\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model Loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper right')\n",
    "  plt.show()\n",
    "#\n",
    "history_plot(history)\n",
    "history_plot(history_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if it does not exist\n",
    "\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(f\"{dir_name}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "y_pred = np.argmax(Predictions, axis=1) + 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Load existing classification reports if the file exists\n",
    "classification_reports_path = f\"{dir_name}/classification_reports.json\"\n",
    "if os.path.exists(classification_reports_path):\n",
    "    with open(classification_reports_path, \"r\") as json_file:\n",
    "        classification_reports = json.load(json_file)\n",
    "else:\n",
    "    classification_reports = {}\n",
    "\n",
    "# Add the current model's classification report\n",
    "classification_reports.append([save_model_version, report_dict])\n",
    "\n",
    "# Sort the classification reports by macro F1-score\n",
    "sorted_reports = sorted(\n",
    "    classification_reports,\n",
    "    key=lambda x: x[1][\"macro avg\"][\"f1-score\"],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Save the updated classification reports\n",
    "with open(classification_reports_path, \"w\") as json_file:\n",
    "    json.dump(sorted_reports, json_file, indent=4)\n",
    "\n",
    "class_dict = {\n",
    "    0: \"Spruce\",\n",
    "    1: \"Pine\",\n",
    "    3: \"Deciduous\"\n",
    "}\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_dict.values(), yticklabels=class_dict.values())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.savefig(f\"{dir_name}/{save_model_version}_confusion_matrix.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
